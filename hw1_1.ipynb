{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tensor Initialization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a679c9c86273a3f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## a_tensor_initialization.py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7e713e525df57ef"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:27:46.176347100Z",
     "start_time": "2023-09-18T12:27:45.379058400Z"
    }
   },
   "id": "43f8f21bb6b68936"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### torch.Tensor class & torch.tensor function\n",
    "> default tensor type of torch.Tensor : float32 <br>\n",
    "> default tensor type of torch.tensor : int64"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cbad6344ea9544d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### troch.Tensor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fb4191e634506ce"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor 클래스로 텐서를 만드는 코드이다.\n",
    "# torch.Tensor class\n",
    "t1 = torch.Tensor([1, 2, 3], device='cpu')\n",
    "print(t1.dtype)   # >>> torch.float32\n",
    "print(t1.device)  # >>> cpu\n",
    "print(t1.requires_grad)  # >>> False\n",
    "print(t1.size())  # torch.Size([3])\n",
    "print(t1.shape)   # torch.Size([3])\n",
    "# 모든 tensor는 device, dtype, shape, required_grad 요소를 가지고 있다.\n",
    "# 위 결과는 이 요소들을 모두 확인하는 코드이다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:27:46.708450800Z",
     "start_time": "2023-09-18T12:27:45.400545300Z"
    }
   },
   "id": "3aeb264e9fc05469"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# if you have gpu device\n",
    "# t1_cuda = t1.to(torch.device('cuda'))\n",
    "# or you can use shorthand\n",
    "# t1_cuda = t1.cuda()\n",
    "t1_cpu = t1.cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:27:46.739497300Z",
     "start_time": "2023-09-18T12:27:45.415330200Z"
    }
   },
   "id": "f46580da795eeafc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 위의 주석은 텐서의 디바이스를 gpu로 바꾸는 코드다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e481654ca288fbe0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### torch.tensor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbb0e986a09e19e0"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# 아래는 torch.tensor 을 이용해 텐서를 만드는 코드이다. \n",
    "# torch.tensor function\n",
    "t2 = torch.tensor([1, 2, 3], device='cpu')\n",
    "print(t2.dtype)  # >>> torch.int64\n",
    "print(t2.device)  # >>> cpu\n",
    "print(t2.requires_grad)  # >>> False\n",
    "print(t2.size())  # torch.Size([3])\n",
    "print(t2.shape)  # torch.Size([3])\n",
    "\n",
    "# if you have gpu device\n",
    "# t2_cuda = t2.to(torch.device('cuda'))\n",
    "# or you can use shorthand\n",
    "# t2_cuda = t2.cuda()\n",
    "t2_cpu = t2.cpu()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:27:46.771721900Z",
     "start_time": "2023-09-18T12:27:45.431507100Z"
    }
   },
   "id": "415d7dc7b8630028"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- dtype을 보면 torch.Tensor와 다르게 int64임을 확인할 수 있다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9fa32908f6cb5409"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Size & ndims of Tensor"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2104840199b64ae3"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) 0\n",
      "torch.Size([1]) 1\n",
      "torch.Size([5]) 1\n",
      "torch.Size([5, 1]) 2\n"
     ]
    }
   ],
   "source": [
    "a1 = torch.tensor(1)\t\t\t     # shape: torch.Size([]), ndims(=rank): 0\n",
    "print(a1.shape, a1.ndim)\n",
    "\n",
    "a2 = torch.tensor([1])\t\t  \t     # shape: torch.Size([1]), ndims(=rank): 1\n",
    "print(a2.shape, a2.ndim)\n",
    "\n",
    "a3 = torch.tensor([1, 2, 3, 4, 5])   # shape: torch.Size([5]), ndims(=rank): 1\n",
    "print(a3.shape, a3.ndim)\n",
    "\n",
    "a4 = torch.tensor([[1], [2], [3], [4], [5]])   # shape: torch.Size([5, 1]), ndims(=rank): 2\n",
    "print(a4.shape, a4.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:27:46.807539500Z",
     "start_time": "2023-09-18T12:27:45.448546600Z"
    }
   },
   "id": "9fda13a7148315b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 1과 [1]은 다르다. 대괄호 [] 하나가 한 차원이라고 생각하면 된다.\n",
    "- 따라서 a2과 a3 모두 1차원이다.\n",
    "> <p style=\"font-style:italic\"> tip . ndim을 세는 법은 연속적으로 [가 나타나는 횟수를 세면 된다. </p> \n",
    "\n",
    "- shape은 각 차원의 요소들의 개수이다. 가장 바깥쪽 괄호의 차원부터 적는다.\n",
    "- a4의 shape은 가장 바깥쪽 [] 안의 요소가 5, 그 다음 [] 안의 요소는 1개 이므로 [5,1]이 된다. \n",
    "> <p style=\"font-style:italic\"> tip . shape 찾는 방법은 가장 작게 있는 요소들 부터 수를 세고 반대로 적으면 된다. (안쪽 괄호부터 찾는 것이 더 편할 경우) </p>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af866e0a61171459"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) 2\n"
     ]
    }
   ],
   "source": [
    "a5 = torch.tensor([                 # shape: torch.Size([3, 2]), ndims(=rank): 2\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6]\n",
    "])\n",
    "print(a5.shape, a5.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:27:46.832132500Z",
     "start_time": "2023-09-18T12:27:45.461871600Z"
    }
   },
   "id": "2b7111ccdf0dfbfe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 위 텐서는 [ [], [], [], ] 으로 이루어져 있으므로 2차원이다.\n",
    "- 가장 바깥쪽 [] 안의 요소는 3개, 그 다음 [] 안의 요소는 2개 이므로 이 텐서의 shape은 [3,2]이다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf2733bb4c42ec70"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 1]) 3\n"
     ]
    }
   ],
   "source": [
    "a6 = torch.tensor([                 # shape: torch.Size([3, 2, 1]), ndims(=rank): 3\n",
    "    [[1], [2]],\n",
    "    [[3], [4]],\n",
    "    [[5], [6]]\n",
    "])\n",
    "print(a6.shape, a6.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:27:46.846294600Z",
     "start_time": "2023-09-18T12:27:45.501422Z"
    }
   },
   "id": "1508360f6a2c06d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 위 텐서는 [ [[] []], [[] []], [[] []], ] 으로 이루어져 있으므로 3차원이다.\n",
    "- 가장 바깥쪽 [] 안의 요소는 3개, 그 다음 [] 안의 요소는 2개, 그 다음 [] 안의 요소는 1개 이므로 이 텐서의 shape은 [3,2,1]이다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0b18875832ff066"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 1]) 4\n"
     ]
    }
   ],
   "source": [
    "a7 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 1]), ndims(=rank): 4\n",
    "    [[[1], [2]]],\n",
    "    [[[3], [4]]],\n",
    "    [[[5], [6]]]\n",
    "])\n",
    "print(a7.shape, a7.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:27:46.873726300Z",
     "start_time": "2023-09-18T12:27:45.554788Z"
    }
   },
   "id": "eff83814f8d2cb54"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 위 텐서는 연속으로 [가 4번 나오므로 4차원이다. \n",
    "- 가장 안쪽 괄호부터 차원의 요소를 세면 1, 2, 1, 3 이다. 따라서 shape 은 [3,1,2,1]이다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba89f4906a40e195"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 3]) 4\n"
     ]
    }
   ],
   "source": [
    "a8 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 3]), ndims(=rank): 4\n",
    "    [[[1, 2, 3], [2, 3, 4]]],\n",
    "    [[[3, 1, 1], [4, 4, 5]]],\n",
    "    [[[5, 6, 2], [6, 3, 1]]]\n",
    "])\n",
    "print(a8.shape, a8.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:27:46.893021300Z",
     "start_time": "2023-09-18T12:27:45.571401800Z"
    }
   },
   "id": "d98ad6343cff7dfb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 위 텐서는 연속으로 [가 4번 나오므로 4차원이다. \n",
    "- 가장 안쪽 괄호부터 차원의 요소를 세면 3, 2, 1, 3 이다. 따라서 shape 은 [3,1,2,3]이다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b5b16cc1460357b"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 3, 1]) 5\n"
     ]
    }
   ],
   "source": [
    "a9 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 3, 1]), ndims(=rank): 5\n",
    "    [[[[1], [2], [3]], [[2], [3], [4]]]],\n",
    "    [[[[3], [1], [1]], [[4], [4], [5]]]],\n",
    "    [[[[5], [6], [2]], [[6], [3], [1]]]]\n",
    "])\n",
    "print(a9.shape, a9.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:27:46.914220400Z",
     "start_time": "2023-09-18T12:27:45.586350300Z"
    }
   },
   "id": "28eef98b687b97bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 위 텐서는 연속으로 [가 5번 나오므로 ndims = 5 다.\n",
    "- 안쪽 괄호부터 요소를 세면 1,3,2,1,3 이므로 shape은 [3,1,2,3,1]이다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79c320462ae10128"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 5]) 2\n"
     ]
    }
   ],
   "source": [
    "a10 = torch.tensor([                 # shape: torch.Size([4, 5]), ndims(=rank): 2\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "])\n",
    "print(a10.shape, a10.ndim)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:27:46.923698300Z",
     "start_time": "2023-09-18T12:27:45.600090300Z"
    }
   },
   "id": "20292798fade690d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 위 텐서는 연속으로 [가 두번 나오므로 ndims=2이다. \n",
    "- 안쪽 괄호부터 요소는 5, 4 씩 있으므로 shape 은 [4,5]이다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbc80a72c6b7f8f2"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 3 at dim 3 (got 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 불균일한 형태의 리스트를 텐서로 입력받으면 에러가 발생한다. \u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# torch는 균일한 형태의 리스트만을 생성한다. \u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m a11 \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m                 \u001B[49m\u001B[38;5;66;43;03m# ValueError: expected sequence of length 3 at dim 3 (got 2)\u001B[39;49;00m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      8\u001B[0m \u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: expected sequence of length 3 at dim 3 (got 2)"
     ]
    }
   ],
   "source": [
    "# 불균일한 형태의 리스트를 텐서로 입력받으면 에러가 발생한다. \n",
    "# torch는 균일한 형태의 리스트만을 생성한다. \n",
    "a11 = torch.tensor([                 # ValueError: expected sequence of length 3 at dim 3 (got 2)\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:27:47.052177500Z",
     "start_time": "2023-09-18T12:27:45.614446100Z"
    }
   },
   "id": "bd08bcb5c9e4513f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 위 텐서를 실행하면 ValueError: expected sequence of length 3 at dim 3 (got 2) 에러가 발생한다. \n",
    "- torch는 균일한 현태의 텐서만을 생성할 수 있다. 즉, 리스트안의 리스트 길이가 일정해야한다. 그러나 예시의 리스트는 불규칙한 형태의 다차원 배열이기 때문에 에러가 발생한다. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "907e145d8089af69"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## b_tensor_initialization_copy.py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61b9f4cbba2a0dd4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- torch.Tensor와 torch.tensor는 항상 주어진 데이터를 복사한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa8b2a0dfe95edc3"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# numpy array 없이 리스트를 생성해서 torch로 텐서를 만들면, 이 텐서는 복사가 된다. \n",
    "l1 = [1, 2, 3]\n",
    "t1 = torch.Tensor(l1)\n",
    "\n",
    "l2 = [1, 2, 3]\n",
    "t2 = torch.tensor(l2)\n",
    "\n",
    "l3 = [1, 2, 3]\n",
    "t3 = torch.as_tensor(l3)\n",
    "\n",
    "l1[0] = 100  # 이 코드에서 리스트의 값을 변경하면\n",
    "l2[0] = 100\n",
    "l3[0] = 100\n",
    "\n",
    "print(t1)   # 텐서의 값은 변경되지 않는다. \n",
    "print(t2)\n",
    "print(t3)\n",
    "# 이는 torch.Tensor와 torch.tensor가 항상 데이터를 복사하기 때문이다. "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:27:58.449209700Z",
     "start_time": "2023-09-18T12:27:58.421730700Z"
    }
   },
   "id": "32b05cb065a64121"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# 그러나 numpy array를 사용하여 배열을 만들고, 이를 torch.as_tensorO()메소드로 텐서화 시키면 copy를 피할 수 있다. "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:27:58.971643100Z",
     "start_time": "2023-09-18T12:27:58.940784800Z"
    }
   },
   "id": "29d9db55e799cc94"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([100,   2,   3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "l4 = np.array([1, 2, 3])\n",
    "t4 = torch.Tensor(l4)\n",
    "\n",
    "l5 = np.array([1, 2, 3])\n",
    "t5 = torch.tensor(l5)\n",
    "\n",
    "l6 = np.array([1, 2, 3])\n",
    "t6 = torch.as_tensor(l6)\n",
    "\n",
    "l4[0] = 100 # l4와 l5의 값은 변하지 않으나\n",
    "l5[0] = 100\n",
    "l6[0] = 100 # l6의 값은 100으로 변함을 출력값에서 확인할 수 있다. \n",
    "\n",
    "print(t4)\n",
    "print(t5)\n",
    "print(t6)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:27:59.536457Z",
     "start_time": "2023-09-18T12:27:59.413650400Z"
    }
   },
   "id": "c3d095985066ee54"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## c_tensor_initialization_constant_values.py\n",
    "> 값을 넣어서 텐서를 초기화 하기."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19a496d142dd916d"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# import torch\n",
    "# 위의 a_initialization.py 파트에서 torch를 import 하였으므로 앞으로 임포트 문은 생략한다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:00.308075900Z",
     "start_time": "2023-09-18T12:28:00.268790800Z"
    }
   },
   "id": "93086ce0c1b1ae8a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- torch.ones(*size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6f7a4339eef2772"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# 사이즈가 (5,)이고, 값이 모두 1인 텐서를 생성\n",
    "t1 = torch.ones(size=(5,))  # or torch.ones(5): 여기서 size=(5,)를 5로 생략이 가능하다.\n",
    "# t1과 동일한 차원과 크기이며, 값이 모두 1인 텐서 생성\n",
    "t1_like = torch.ones_like(input=t1)\n",
    "print(t1)  # >>> tensor([1., 1., 1., 1., 1.])\n",
    "print(t1_like)  # >>> tensor([1., 1., 1., 1., 1.])\n",
    "# 두 텐서의 출력 결과는 같다. "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:00.881731200Z",
     "start_time": "2023-09-18T12:28:00.823701400Z"
    }
   },
   "id": "e7535ab4519a5f09"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- torch.zeros"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc8f5b8cfd331591"
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# 사이즈가 (6,)이고, 값이 모두 0인 텐서를 생성\n",
    "t2 = torch.zeros(size=(6,))  # or torch.zeros(6)\n",
    "# t2과 동일한 차원과 크기이며. 값이 모두 0인 텐서 생성\n",
    "t2_like = torch.zeros_like(input=t2)\n",
    "print(t2)  # >>> tensor([0., 0., 0., 0., 0., 0.])\n",
    "print(t2_like)  # >>> tensor([0., 0., 0., 0., 0., 0.])\n",
    "# 두 텐서의 출력 결과는 같다. "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:01.230598700Z",
     "start_time": "2023-09-18T12:28:01.189872800Z"
    }
   },
   "id": "e66e24550d09d06e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- torch.empty"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d554cc80f097606d"
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4610e-33, 4.5915e-41, 1.3381e+34, 1.0089e-42])\n",
      "tensor([5.3689e+08, 5.0944e-14, 1.5039e-33, 4.5915e-41])\n"
     ]
    }
   ],
   "source": [
    "# 사이즈가 (4,)이고, 초기화 되지 않은 값을 넣어서 텐서 생성.\n",
    "# 그러나 대부분의 값이 0이다. \n",
    "t3 = torch.empty(size=(4,))  # or torch.zeros(4)\n",
    "# t3과 동일한 차원과 크기이며. 초기화 되지 않은 값을 넣어서 생성\n",
    "t3_like = torch.empty_like(input=t3)\n",
    "print(t3)  # >>> tensor([0., 0., 0., 0.])\n",
    "print(t3_like)  # >>> tensor([0., 0., 0., 0.])\n",
    "# 초기화 되지 않은 값을 넣어 생성하였으므로\n",
    "# 두 텐서의 출력이 다름을 확인 할 수 있다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:01.577999100Z",
     "start_time": "2023-09-18T12:28:01.526211Z"
    }
   },
   "id": "9503307b0e37fa58"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- torch.eye"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6548802b0b0f177b"
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.eye(n)은 크기가 n인 단위행렬을 생성하는 메소드다.\n",
    "t4 = torch.eye(n=3)\n",
    "print(t4)\n",
    "# 출력과 같이 대각선 방향으로만 1이고 나머지는 모두 0임을 볼 수 있다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:01.887456Z",
     "start_time": "2023-09-18T12:28:01.818825200Z"
    }
   },
   "id": "41c21f9c736dec20"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## d_tensor_initialization_random_values.py\n",
    "> random 값을 넣어서 텐서 초기화 하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6c87f00e5c26439"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- torch.randint(low=0, high, size, ...)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdef7738dbdbda11"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19, 18]])\n"
     ]
    }
   ],
   "source": [
    "# low와 high 사이의 정수 값들을 균일하게 생성한다. - integer uniform \n",
    "t1 = torch.randint(low=10, high=20, size=(1, 2))\n",
    "print(t1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:02.335616100Z",
     "start_time": "2023-09-18T12:28:02.256364300Z"
    }
   },
   "id": "cb9edbc2e7962ede"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- torch.rand(*size,...)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e6cb5e23eabe800"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3347, 0.0177, 0.5295]])\n"
     ]
    }
   ],
   "source": [
    "# 0과 1사이의 uniform distribution로 부터 float 값을 생성한다. \n",
    "t2 = torch.rand(size=(1, 3))\n",
    "print(t2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:02.640086400Z",
     "start_time": "2023-09-18T12:28:02.550669700Z"
    }
   },
   "id": "66a3a6dae47270e2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- torch.randn(*size,...)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c50d6fd00d065c55"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3992,  0.5168, -0.5287]])\n"
     ]
    }
   ],
   "source": [
    "# 0과 1 사이의 표준 정규 분포도(standard normal distribution)로 부터 랜덤한 float 값을 생성한다. \n",
    "t3 = torch.randn(size=(1, 3))\n",
    "print(t3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:02.886290200Z",
     "start_time": "2023-09-18T12:28:02.819187800Z"
    }
   },
   "id": "b567948680db96a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- torch.normal(mean, std, size, ...)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a4c99c1dcbcdaf2"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.3028, 11.3705],\n",
      "        [10.8893,  8.7839],\n",
      "        [11.6274,  8.9572]])\n"
     ]
    }
   ],
   "source": [
    "# 매개변수로 주어진 mean과 std, size를 갖는 정규 분포도로 부터 랜덤한 값을 생성한다. \n",
    "t4 = torch.normal(mean=10.0, std=1.0, size=(3, 2))\n",
    "print(t4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:03.156342600Z",
     "start_time": "2023-09-18T12:28:03.092691Z"
    }
   },
   "id": "a256bae80260389f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- torch.linspace(start,end,steps, ...)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "429aec55b81b9d68"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 2.5000, 5.0000])\n"
     ]
    }
   ],
   "source": [
    "# start 부터 end 까지, 개수는 3인 동일한 간격의 1차원 텐서를 생성한다. \n",
    "t5 = torch.linspace(start=0.0, end=5.0, steps=3)\n",
    "print(t5)\n",
    "# 0부터 5까지 3개의 값이어야 하므로\n",
    "# 0, 2.5, 5를 반환한다. "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:03.425989300Z",
     "start_time": "2023-09-18T12:28:03.356549100Z"
    }
   },
   "id": "f2e3245bcf3ab652"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- torch.arange(start=0, end, step=1, ...)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d16e511659751bd"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# start 부터 end-1 까지 간격이 1인 1차원 텐서를 생성한다.  \n",
    "t6 = torch.arange(5)\n",
    "print(t6)\n",
    "# 4까지만 출력됨을 볼 수 있다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:03.667802300Z",
     "start_time": "2023-09-18T12:28:03.613161200Z"
    }
   },
   "id": "db558ca0f67ddac0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- torch.manual_seed(value)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "38be6853a17af6a1"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n",
      "\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n"
     ]
    }
   ],
   "source": [
    "# 난수생성기의 시드값에 고정된 값을 넣어서 생성하면, 같은 값을 다시 생성할 수 있다.\n",
    "torch.manual_seed(1729) # 시드값으로 1729를 준다. \n",
    "random1 = torch.rand(2, 3)\n",
    "print(random1)\n",
    "\n",
    "random2 = torch.rand(2, 3)\n",
    "print(random2)\n",
    "# 두 텐서의 값을 다르게 나온다.\n",
    "print()\n",
    "\n",
    "torch.manual_seed(1729) # 다시 시드를 주고\n",
    "random3 = torch.rand(2, 3) # 텐서를 생성하면, 위의 텐서와 같은 텐서가 출력된다. \n",
    "print(random3)\n",
    "\n",
    "random4 = torch.rand(2, 3)\n",
    "print(random4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:04.015407600Z",
     "start_time": "2023-09-18T12:28:03.879535400Z"
    }
   },
   "id": "bdfd9c2e295ab419"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---\n",
    "# Tensor Operations\n",
    "---\n",
    "---\n",
    "## e_tensor_type_conversion.py\n",
    "> 텐서의 형변환"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "215202595e9ae8e5"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n",
      "tensor([[18.0429,  7.2532, 19.6519],\n",
      "        [10.8626,  2.1505, 19.6913]], dtype=torch.float64)\n",
      "tensor([[18,  7, 19],\n",
      "        [10,  2, 19]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2, 3)) # 1으로 채워진 텐서 생성\n",
    "print(a.dtype)  # torch.ones 로 텐서를 생성하면 default dtype은 float32이다.\n",
    "\n",
    "b = torch.ones((2, 3), dtype=torch.int16) # 텐서를 생성할 때 dtype을 지정할 수 있다.\n",
    "print(b) # 출력할 때, dtype도 같이 출력됨\n",
    "\n",
    "c = torch.rand((2, 3), dtype=torch.float64) * 20. # -> broadcasting \n",
    "print(c) # broadcasting을 해도 dtype은 똑같다.\n",
    "\n",
    "d =c.to(torch.int32) # 텐서 c의 dtype을 int32로 바꾼다.\n",
    "print(d)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:04.226822Z",
     "start_time": "2023-09-18T12:28:04.150511500Z"
    }
   },
   "id": "f4a5588fcf0b6227"
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.int16\n"
     ]
    }
   ],
   "source": [
    "# 인자로 dtype 값을 주어서 형식을 지정할 수 있다.\n",
    "double_d = torch.ones(10, 2, dtype=torch.double)\n",
    "short_e = torch.tensor([[1, 2]], dtype=torch.short)\n",
    "# 메소드로 형식을 지정할 수 있다.\n",
    "double_d = torch.zeros(10, 2).double()\n",
    "short_e = torch.ones(10, 2).short()\n",
    "\n",
    "# .to(dtype) 으로 형식을 바꿀 수 있다.\n",
    "double_d = torch.zeros(10, 2).to(torch.double)\n",
    "short_e = torch.ones(10, 2).to(dtype=torch.short)\n",
    "\n",
    "double_d = torch.zeros(10, 2).type(torch.double)\n",
    "short_e = torch.ones(10, 2). type(dtype=torch.short)\n",
    "\n",
    "print(double_d.dtype)\n",
    "print(short_e.dtype)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:04.353712800Z",
     "start_time": "2023-09-18T12:28:04.289844Z"
    }
   },
   "id": "83376a03e6309522"
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "# double 타입으로 생성한 텐서를 short 타입으로 바꾸는 코드\n",
    "double_f = torch.rand(5, dtype=torch.double)\n",
    "short_g = double_f.to(torch.short)\n",
    "print((double_f * short_g).dtype) \n",
    "# double type * short type => double type"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:04.592661700Z",
     "start_time": "2023-09-18T12:28:04.525488Z"
    }
   },
   "id": "428a51bf8f91a695"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## f_tensor_operations.py\n",
    "> 텐서의 기본 연산"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2254d0346661a5d"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "t1 = torch.ones(size=(2, 3))\n",
    "t2 = torch.ones(size=(2, 3))\n",
    "# 1로 채워진 size가 (2,3)인 텐서 두개 생성"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:04.853704100Z",
     "start_time": "2023-09-18T12:28:04.819918100Z"
    }
   },
   "id": "d90e36517bbd3177"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# 두 텐서의 합\n",
    "t3 = torch.add(t1, t2) # add 메소드\n",
    "t4 = t1 + t2           # + 연산자\n",
    "print(t3)\n",
    "print(t4)\n",
    "# 결과가 같다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:05.006820500Z",
     "start_time": "2023-09-18T12:28:04.967626900Z"
    }
   },
   "id": "bacc7adc0f47e3bd"
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 두 텐서의 차\n",
    "t5 = torch.sub(t1, t2) # sub 메소드\n",
    "t6 = t1 - t2           # - 연산자\n",
    "print(t5)\n",
    "print(t6)\n",
    "# 결과가 같다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:05.142743800Z",
     "start_time": "2023-09-18T12:28:05.111199300Z"
    }
   },
   "id": "de275489e345252"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 두 텐서의 곱\n",
    "t7 = torch.mul(t1, t2) # mul 메소드\n",
    "t8 = t1 * t2           # * 연산자\n",
    "print(t7)\n",
    "print(t8)\n",
    "# 결과가 같다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:05.337263Z",
     "start_time": "2023-09-18T12:28:05.274319500Z"
    }
   },
   "id": "87bb53cbb4fd47dc"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 두 텐서의 나눗셈\n",
    "t9 = torch.div(t1, t2) # div 메소드   \n",
    "t10 = t1 / t2          # / 연산자\n",
    "print(t9)\n",
    "print(t10)\n",
    "# 결과가 같다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:05.535433800Z",
     "start_time": "2023-09-18T12:28:05.426608300Z"
    }
   },
   "id": "a10084b08d37a52b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## g_tensor_operations_mm.py\n",
    "> 텐서의 행렬 곱1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbafc5d9f0cec12d"
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# 두 1차원 텐서의 dot product(내적)\n",
    "t1 = torch.dot(\n",
    "  torch.tensor([2, 3]), torch.tensor([2, 1])\n",
    ")\n",
    "print(t1, t1.size())\n",
    "# 2*2 + 3*1 = 7 이므로 t1은 7이 출력된다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:05.739290800Z",
     "start_time": "2023-09-18T12:28:05.700179400Z"
    }
   },
   "id": "b3cf661c2126b38"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6750, 2.2840],\n",
      "        [0.0956, 1.0294]]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# broadcasting 없이 2차원 텐서의 행렬곱 연산.\n",
    "# nxm 행렬과 mxp 행렬이 곱해지면 nxp 행렬을 반환한다. \n",
    "t2 = torch.randn(2, 3)\n",
    "t3 = torch.randn(3, 2)\n",
    "t4 = torch.mm(t2, t3)\n",
    "print(t4, t4.size())\n",
    "# 따라서 t4의 Size는 [2,2]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:05.906035900Z",
     "start_time": "2023-09-18T12:28:05.859155300Z"
    }
   },
   "id": "ee15d252031b0096"
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# broadcasting없이 batch 행렬의 곱연산\n",
    "# bxnxm 행렬과 bxmxp 행렬이 곱해지면 bxnxp 행렬을 반환한다. \n",
    "t5 = torch.randn(10, 3, 4) # 3차원 행렬\n",
    "t6 = torch.randn(10, 4, 5)\n",
    "t7 = torch.bmm(t5, t6)\n",
    "print(t7.size())\n",
    "# size는 [10, 3, 5]이다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:06.097483100Z",
     "start_time": "2023-09-18T12:28:06.022725Z"
    }
   },
   "id": "4b73c326fc6fb4a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## h_tensor_operations_matmul.py\n",
    "> 텐서의 행렬곱2\n",
    "> matmul 연산은 텐서의 모양에 따라 다른 방법으로 연산을 수행한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b99956c44d418584"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# 1차원 텐서는 dot product를 한다. \n",
    "# vector x vector: dot product \n",
    "t1 = torch.randn(3)\n",
    "t2 = torch.randn(3)\n",
    "print(torch.matmul(t1, t2).size())  # torch.Size([])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:06.329636800Z",
     "start_time": "2023-09-18T12:28:06.275163200Z"
    }
   },
   "id": "76bc5f3aa8d5060a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1차원 행렬의 dot product 연산(내적)은 결과가 행렬이 아니므로 size는 []이다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c11c445f84ec7dec"
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# 2차원 텐서와 1차원 텐서의 행렬곱은 크기가 다르므로\n",
    "# broadcated dot 연산을 한다.\n",
    "\n",
    "# size=(4)인 t4를 t3의 각 행에 내적하면 \n",
    "# 이것이 broadcasted dot 연산이다. \n",
    "# matrix x vector: broadcasted dot\n",
    "t3 = torch.randn(3, 4)\n",
    "t4 = torch.randn(4)\n",
    "print(torch.matmul(t3, t4).size())  # torch.Size([3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:06.661602400Z",
     "start_time": "2023-09-18T12:28:06.568249500Z"
    }
   },
   "id": "3ef050ef2940c87e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "t4가 t3의 각 행에 dot product 연산을 하면 각 행의 값은\n",
    "스칼라가 되므로 size는 ([3])이 된다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abfa7b00433811f4"
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "# 3차원 행렬ㄹ과 벡터의 연산 또한 broadcasted dot 연산이 된다.\n",
    "\n",
    "# t6은 t5의 모든 [10,3]에 product 연산을 한다. 따라서\n",
    "# 연산 결과의 Size는 [10,3]이다.\n",
    "# batched matrix x vector: broadcasted dot\n",
    "t5 = torch.randn(10, 3, 4) \n",
    "t6 = torch.randn(4) # matmul 연산에서 [4,1] 로 확장\n",
    "print(torch.matmul(t5, t6).size())  # torch.Size([10, 3]) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:06.918243300Z",
     "start_time": "2023-09-18T12:28:06.862035600Z"
    }
   },
   "id": "9b56951a56309596"
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# 두 3차원 행렬의 행렬곱이다.\n",
    "# dim=0의 값이 같으므로 \n",
    "# bmm 연산은 (10,3,5)가 된다.\n",
    "\n",
    "# bmm 연산: (b x n x m)by(b x m x p)-> (b x n x p)\n",
    "# batched matrix x batched matrix: bmm\n",
    "t7 = torch.randn(10, 3, 4)\n",
    "t8 = torch.randn(10, 4, 5)\n",
    "print(torch.matmul(t7, t8).size())  # torch.Size([10, 3, 5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:07.104526900Z",
     "start_time": "2023-09-18T12:28:07.042312100Z"
    }
   },
   "id": "2aaeab1a15bc945"
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# 3차원 행렬과 2차원 행렬의 연산 또한 bmm 연산이다.\n",
    "# 따라서 결과는 [10,3,5]이다.\n",
    "\n",
    "# batched matrix x matrix: bmm\n",
    "t9 = torch.randn(10, 3, 4)\n",
    "t10 = torch.randn(4, 5)\n",
    "print(torch.matmul(t9, t10).size())  # torch.Size([10, 3, 5])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:07.272046200Z",
     "start_time": "2023-09-18T12:28:07.179995600Z"
    }
   },
   "id": "35592386504e253b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## i_tensor_broadcasting.py\n",
    "> 브로드캐스팅이란 더 작은 텐서를 더 큰 텐서에 맞춰 브로드캐스트되어 호환 가능한 모양을 가지며 요소별로 연산을 수행하는 것이다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a7d1fc15ae2b335"
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6.])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "t2 = 2.0\n",
    "print(t1 * t2) # 각 요소에 2.0이 곱해진다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:07.535571400Z",
     "start_time": "2023-09-18T12:28:07.453820400Z"
    }
   },
   "id": "90935e649256918a"
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-4, -4],\n",
      "        [-2, -1],\n",
      "        [ 6,  5]])\n"
     ]
    }
   ],
   "source": [
    "t3 = torch.tensor([[0, 1], [2, 4], [10, 10]])\n",
    "t4 = torch.tensor([4, 5])\n",
    "print(t3 - t4) # 각 행에 t4의 - 연산이 수행된다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:07.699313Z",
     "start_time": "2023-09-18T12:28:07.608032600Z"
    }
   },
   "id": "d151b2fc3fd1315e"
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[-1.,  0.],\n",
      "        [ 1.,  2.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[0.5000, 1.0000],\n",
      "        [1.5000, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.tensor([[1., 2.], [3., 4.]])\n",
    "print(t5 + 2.0)  # t5.add(2.0)\n",
    "print(t5 - 2.0)  # t5.sub(2.0)\n",
    "print(t5 * 2.0)  # t5.mul(2.0)\n",
    "print(t5 / 2.0)  # t5.div(2.0)\n",
    "# 같은 텐서가 아닌 상수로 브로드캐스트가 가능하다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:07.852058300Z",
     "start_time": "2023-09-18T12:28:07.783142700Z"
    }
   },
   "id": "74d257054c7451a6"
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "def normalize(x): # 정규화 \n",
    "  return x / 255\n",
    "\n",
    "t6 = torch.randn(3, 28, 28)\n",
    "print(normalize(t6).size()) # 사이즈는 똑같지만 요소는 정규화 된다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:08.127433300Z",
     "start_time": "2023-09-18T12:28:07.904366700Z"
    }
   },
   "id": "7fcaf7b6a6e03ff9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### broadcasting rules\n",
    "- 각 텐서에는 차원이 하나 이상 있어야하며 비어있는 텐서는 없다.\n",
    "- 두 텐서의 차원의 크기는 뒤에서 부터 비교한다.\n",
    "> 각 차원은 동일하거나, 차원중 하나의 크기가 1 이어야한다. \n",
    "> 또는 텐서 중 하나에 차원이 없어야 한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "575019f96d65081a"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 3],\n",
      "        [3, 4]])\n",
      "tensor([[6, 7],\n",
      "        [2, 5]])\n",
      "tensor([[8, 6],\n",
      "        [5, 3]])\n",
      "tensor([[ 8,  9],\n",
      "        [ 7, 10]])\n"
     ]
    }
   ],
   "source": [
    "t7 = torch.tensor([[1, 2], [0, 3]])  # torch.Size([2, 2])\n",
    "t8 = torch.tensor([[3, 1]])  # torch.Size([1, 2])\n",
    "t9 = torch.tensor([[5], [2]])  # torch.Size([2, 1])\n",
    "t10 = torch.tensor([7])  # torch.Size([1])\n",
    "print(t7 + t8)   # t8의 차원이 하나가 1이다.\n",
    "print(t7 + t9)   # t9의 차원의 하나가 1이다. \n",
    "print(t8 + t9)   # t8과 t9 모두 차원이 1이 있다.\n",
    "print(t7 + t10)  # t10이 차원이 1이다.\n",
    "# 따라서 위 네가지는 모두 브로드 캐스팅이 가능하다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:08.385428600Z",
     "start_time": "2023-09-18T12:28:08.218513200Z"
    }
   },
   "id": "71c34f3c7bcb8cc9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- 브로드캐스팅에서 두 차원은 뒤에서 부터 비교한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c49980444bdb7816"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# 뒤에서부터 비교한다.\n",
    "t11 =    torch.ones(4, 3, 2)\n",
    "t12 = t11 * torch.rand(3, 2)  # 3rd & 2nd dims identical to t11, dim 0 absent\n",
    "# 뒤 쪽의 두 차원의 크기가 같으므로 브로드캐스팅이 가능하다.\n",
    "print(t12.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:08.567120900Z",
     "start_time": "2023-09-18T12:28:08.484244200Z"
    }
   },
   "id": "d938f68559e9714a"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# t13에 차원의 크기가 1인 차원이 존재하므로 브로드캐스팅이 가능하다.\n",
    "t13 =    torch.ones(4, 3, 2)\n",
    "t14 = t13 * torch.rand(3, 1)  # 3rd dim = 1, 2nd dim is identical to t13\n",
    "print(t14.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:08.723997700Z",
     "start_time": "2023-09-18T12:28:08.663831600Z"
    }
   },
   "id": "2688aaa2305cea81"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# t16에 사이즈가 1인 차원이 존재하므로 브로드 캐스팅이 가능하다.\n",
    "t15 =    torch.ones(4, 3, 2)\n",
    "t16 = t15 * torch.rand(1, 2)  # 3rd dim is identical to t15, 2nd dim is 1\n",
    "print(t16.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:08.897802800Z",
     "start_time": "2023-09-18T12:28:08.817949Z"
    }
   },
   "id": "6d039aafb775d512"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "# t18에 사이즈가 1인 차원이 존재하므로 브로드 캐스팅이 가능하다. (dim=2의 1)\n",
    "t17 = torch.ones(5, 3, 4, 1)\n",
    "t18 =    torch.rand(3, 1, 1)  # 2nd dim is identical to t17, 3rd and 4th dims are 1\n",
    "print((t17 + t18).size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:09.055089300Z",
     "start_time": "2023-09-18T12:28:08.982208800Z"
    }
   },
   "id": "a9db395171da3716"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "# t19의 dim=1에 사이즈가 1인 차원이 존재하고\n",
    "# t20에도 사이즈가 1인 차원이 존재하므로 브로드캐스팅이 가능하다.\n",
    "t19 = torch.empty(5, 1, 4, 1)\n",
    "t20 =    torch.empty(3, 1, 1)\n",
    "print((t19 + t20).size())  # torch.Size([5, 3, 4, 1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:09.189421200Z",
     "start_time": "2023-09-18T12:28:09.116750400Z"
    }
   },
   "id": "efc6e839ccabeb60"
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 7])\n"
     ]
    }
   ],
   "source": [
    "# 두 텐서중 차원 사이즈가 1인 텐서가 있으면 브로드 캐스팅이 가능하다.\n",
    "t21 =       torch.empty(1)\n",
    "t22 = torch.empty(3, 1, 7)\n",
    "print((t21 + t22).size())  # torch.Size([3, 1, 7])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:09.329413900Z",
     "start_time": "2023-09-18T12:28:09.282913400Z"
    }
   },
   "id": "ecb122109b6cc294"
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# t24에 사이즈가 1인 차원이 있으므로 브로드 캐스팅이 가능하다.\n",
    "t23 = torch.ones(3, 3, 3)\n",
    "t24 = torch.ones(3, 1, 3)\n",
    "print((t23 + t24).size())  # torch.Size([3, 3, 3])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:09.515555800Z",
     "start_time": "2023-09-18T12:28:09.439506900Z"
    }
   },
   "id": "a55a47795eba8dd2"
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[106], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m t25 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mempty(\u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m      4\u001B[0m t26 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mempty(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28mprint\u001B[39m((\u001B[43mt25\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mt26\u001B[49m)\u001B[38;5;241m.\u001B[39msize())\n",
      "\u001B[1;31mRuntimeError\u001B[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "# t26의 dim=1의 차원의 사이즈는 3이고, t25의 dim=1의 차원의 사이즈는 2 이므로\n",
    "# 3은 2의 배수가 아니므로 브로드 캐스팅이 불가능하다.\n",
    "t25 = torch.empty(5, 2, 4, 1)\n",
    "t26 = torch.empty(3, 1, 1)\n",
    "print((t25 + t26).size())\n",
    "# RuntimeError: The size of tensor a (2) must match\n",
    "# the size of tensor b (3) at non-singleton dimension 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:09.768116900Z",
     "start_time": "2023-09-18T12:28:09.585633200Z"
    }
   },
   "id": "9e684c7847ba99dc"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 5., 5., 5.])\n",
      "tensor([25., 25., 25., 25.])\n",
      "tensor([  1.,   4.,  27., 256.])\n"
     ]
    }
   ],
   "source": [
    "# 1로 채워진 텐서에 * 5로 브로드 캐스팅한다.\n",
    "t27 = torch.ones(4) * 5\n",
    "print(t27)  # >>> tensor([ 5, 5, 5, 5])\n",
    "# 그 텐서의 각 값을 제곱시킨다. \n",
    "t28 = torch.pow(t27, 2)\n",
    "print(t28)  # >>> tensor([ 25, 25, 25, 25])\n",
    "\n",
    "exp = torch.arange(1., 5.)  # tensor([ 1.,  2.,  3.,  4.])\n",
    "a = torch.arange(1., 5.)  # tensor([ 1.,  2.,  3.,  4.])\n",
    "t29 = torch.pow(a, exp) # 지수함수로 브로드캐스팅이 가능하다.\n",
    "print(t29)  # >>> tensor([   1.,    4.,   27.,  256.])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:09.818566300Z",
     "start_time": "2023-09-18T12:28:09.734130100Z"
    }
   },
   "id": "7c55ebd0f08b5f55"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## j_tensor_indexing_slicing.py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5228a35e0bb859e5"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 6, 7, 8, 9])\n",
      "tensor([ 1,  6, 11])\n",
      "tensor(7)\n",
      "tensor([ 4,  9, 14])\n"
     ]
    }
   ],
   "source": [
    "# 텐서의 인덱싱: 각 차원에 따라 인덱스를 지정하여 텐서의 개별 요소에 액세스한다.\n",
    "# 텐서의 슬라이싱: 각 차원에 따라 범위를 지정하여 더 큰 텐서에서 특정 하위 텐서를 추출한다.\n",
    "# 고급 인덱싱: 특정 조건에 따라 텐서에서 요소를 선택한다.\n",
    "\n",
    "x = torch.tensor(\n",
    "  [[0, 1, 2, 3, 4],\n",
    "   [5, 6, 7, 8, 9],\n",
    "   [10, 11, 12, 13, 14]]\n",
    ")\n",
    "\n",
    "print(x[1])  # 1행을 선택한다.\n",
    "print(x[:, 1])  # 모든 행에 대하여 1열 이전의 값을 선택한다.\n",
    "print(x[1, 2])  #1행 2열을 선택한다.\n",
    "print(x[:, -1])  # 모든 행에 대하여 마지막 열의 요소들을 선택한다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:10.079243200Z",
     "start_time": "2023-09-18T12:28:10.000541600Z"
    }
   },
   "id": "ed65a35f4c69374"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14]])\n",
      "tensor([[ 8,  9],\n",
      "        [13, 14]])\n"
     ]
    }
   ],
   "source": [
    "print(x[1:])  # 1행부터 모두 선택한다.\n",
    "print(x[1:, 3:])  # 1행부터 3열 이상을 모두 선택한다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:10.306481800Z",
     "start_time": "2023-09-18T12:28:10.170957700Z"
    }
   },
   "id": "7c7fe46c282ddb3d"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.zeros((6, 6)) # 6행 6열의 0으로 채워진 텐서\n",
    "y[1:4, 2] = 1 # 1행부터 3행까지 2열의 요소들을 전부 1로 바꾼다.\n",
    "print(y)\n",
    "\n",
    "print(y[1:4, 1:4]) # 1행부터 3행까지 1열부터 3열까지 출력한다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:10.554419200Z",
     "start_time": "2023-09-18T12:28:10.375861800Z"
    }
   },
   "id": "7b4bbd9f4ae17a67"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [2, 3, 4, 5]])\n",
      "tensor([[3, 4],\n",
      "        [6, 7]])\n",
      "tensor([[2, 3, 4],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [2, 0, 0, 5],\n",
      "        [5, 0, 0, 8]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.tensor(\n",
    "  [[1, 2, 3, 4],\n",
    "   [2, 3, 4, 5],\n",
    "   [5, 6, 7, 8]]\n",
    ")\n",
    "print(z[:2]) # 1행까지 출력한다.\n",
    "print(z[1:, 1:3]) # 1행 이상의 모든 행에 대해 1열 부터 2열까지 출력한다.\n",
    "print(z[:, 1:]) # 모든 행에 대해 1열 이상을 모두 출력한다.\n",
    "\n",
    "z[1:, 1:3] = 0 # 1행 이상의 모든 행에 대해 1열 부터 3열까지 요소를 0으로 바꾼다.\n",
    "print(z)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:10.728766400Z",
     "start_time": "2023-09-18T12:28:10.488475400Z"
    }
   },
   "id": "3eb4c7d537f74c07"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## k_tensor_reshaping.py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9e4a2c582636630"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[1, 2, 3, 4, 5, 6]])\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "# torch.view와 torch.reshape은 요소를 수정하지 않고 텐서의 모양을 바꾸는 함수이다.\n",
    "# 그러나 torch.reshape은 non-contiquous한 텐서의 복사본을 반환할 수 도 있다.\n",
    "\n",
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]]) # Shape = (2,3)\n",
    "t2 = t1.view(3, 2)  # Shape becomes (3, 2)\n",
    "t3 = t1.reshape(1, 6)  # Shape becomes (1, 6)\n",
    "print(t2)\n",
    "print(t3)\n",
    "\n",
    "# 1차원 백터를 torch.view 메소드를 이용해 다른 모양의 텐서로 바꾸는 코드\n",
    "t4 = torch.arange(8).view(2, 4)  # Shape becomes (2, 4)\n",
    "t5 = torch.arange(6).view(2, 3)  # Shape becomes (2, 3)\n",
    "print(t4)\n",
    "print(t5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:11.104551700Z",
     "start_time": "2023-09-18T12:28:10.786031900Z"
    }
   },
   "id": "338a52dcbaee898d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- squeeze(): 차원을 줄이는 함수"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76c4d1813e8cc48d"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "# Original tensor with shape (1, 3, 1)\n",
    "t6 = torch.tensor([[[1], [2], [3]]])\n",
    "\n",
    "# Remove all dimensions of size 1\n",
    "t7 = t6.squeeze()  # Shape becomes (3,)\n",
    "# squeeze함수는 사이즈가 1인 차원을 모두 없애준다.\n",
    "\n",
    "# Remove dimension at position 0: 인자를 넣어서 없앨 차원을 지정할 수 있다.\n",
    "t8 = t6.squeeze(0)  # Shape becomes (3, 1)\n",
    "print(t7)\n",
    "print(t8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:11.248406900Z",
     "start_time": "2023-09-18T12:28:11.063432Z"
    }
   },
   "id": "105d3e647cff0359"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[[1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6]]]) torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "# Original tensor with shape (3,)\n",
    "t9 = torch.tensor([1, 2, 3])\n",
    "\n",
    "# Add a new dimension at position 1: 차원을 늘릴 위치를 지정할 수 있다. \n",
    "t10 = t9.unsqueeze(1)  # Shape becomes (3, 1)\n",
    "print(t10)\n",
    "\n",
    "t11 = torch.tensor( # Original tensor with shape (2, 3)\n",
    "  [[1, 2, 3],\n",
    "   [4, 5, 6]]\n",
    ")\n",
    "t12 = t11.unsqueeze(1)  # Shape becomes (2, 1, 3)\n",
    "print(t12, t12.shape) # dim=1인 자리에 차원을 늘렸으므로 (2, 1, 3)이 된다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:11.548497800Z",
     "start_time": "2023-09-18T12:28:11.191982800Z"
    }
   },
   "id": "7291aa4c5a70c36c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- flatten(): 텐서를 1차원 벡터로 변환한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c153908d83edee9"
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "# Original tensor with shape (2, 3)\n",
    "t13 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Flatten the tensor\n",
    "t14 = t13.flatten()  # Shape becomes (6,)\n",
    "\n",
    "print(t14)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:11.663884400Z",
     "start_time": "2023-09-18T12:28:11.502027600Z"
    }
   },
   "id": "3b40a64840cd5005"
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# Original tensor with shape (2, 2, 2)\n",
    "t15 = torch.tensor([[[1, 2],\n",
    "                     [3, 4]],\n",
    "                    [[5, 6],\n",
    "                     [7, 8]]])\n",
    "t16 = torch.flatten(t15) # 텐서가 1차원 벡터로 바뀐다.\n",
    "\n",
    "t17 = torch.flatten(t15, start_dim=1) # 1차원 이하만 차원이 풀린다.\n",
    "# 즉 2차원의 행렬이 된다.\n",
    "print(t16)\n",
    "print(t17)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:11.881051400Z",
     "start_time": "2023-09-18T12:28:11.610944600Z"
    }
   },
   "id": "e7cd31b09f75dee9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- permute(): 차원 바꾸기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9be99475472001a"
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n",
      "torch.Size([5, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "t18 = torch.randn(2, 3, 5)\n",
    "print(t18.shape)  # >>> torch.Size([2, 3, 5])\n",
    "print(torch.permute(t18, (2, 0, 1)).size())  # >>> torch.Size([5, 2, 3])\n",
    "# 각각 차원이 0 1 2 이므로 2 0 1로 텐서의 차원 사이즈를 바꾸는 함수다.\n",
    "# 따라서 (2, 3, 5) - >(5, 2, 3) 으로 바뀐다."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:12.172718Z",
     "start_time": "2023-09-18T12:28:11.933900700Z"
    }
   },
   "id": "72e7604581be3e5c"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "# Original tensor with shape (2, 3)\n",
    "t19 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Permute the dimensions\n",
    "t20 = torch.permute(t19, dims=(0, 1))  # Shape becomes (2, 3) still\n",
    "t21 = torch.permute(t19, dims=(1, 0))  # Shape becomes (3, 2)\n",
    "# 0번째 차원과 1번째 차원의 크기를 바꾼다.\n",
    "print(t20)\n",
    "print(t21)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:12.276442800Z",
     "start_time": "2023-09-18T12:28:12.057228Z"
    }
   },
   "id": "946e9dd22cd6d3f5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- transpose() : 전치행렬"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3295dba71bd4dd77"
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "# 행과 열을 바꾸는 함수.\n",
    "# Transpose the tensor\n",
    "t22 = torch.transpose(t19, 0, 1)  # Shape becomes (3, 2)\n",
    "print(t22)\n",
    "\n",
    "t23 = torch.t(t19)  # Shape becomes (3, 2)\n",
    "print(t23)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:12.543600700Z",
     "start_time": "2023-09-18T12:28:12.350925400Z"
    }
   },
   "id": "82f617b48b6aa568"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "---\n",
    "# Tensor Stacking\n",
    "---\n",
    "---\n",
    "## l_tensor_concat.py\n",
    "> 특정한 차원에 따라 텐서들을 연결한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afc4d44fc7513991"
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.zeros([2, 1, 3])\n",
    "t2 = torch.zeros([2, 3, 3])\n",
    "t3 = torch.zeros([2, 2, 3])\n",
    "\n",
    "t4 = torch.cat([t1, t2, t3], dim=1) # 1차원에 맞춰서 텐서를 연결한다.\n",
    "print(t4.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:12.825337Z",
     "start_time": "2023-09-18T12:28:12.693324100Z"
    }
   },
   "id": "479d2e7d55073042"
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.arange(0, 3)  # tensor([0, 1, 2])\n",
    "t6 = torch.arange(3, 8)  # tensor([3, 4, 5, 6, 7])\n",
    "\n",
    "t7 = torch.cat((t5, t6), dim=0) # 0차원에 맞춰서 텐서를 연결한다.\n",
    "# 두 차원 모두 1차원 벡터이므로 결과는 1차원 벡터가 된다.\n",
    "print(t7.shape)  # >>> torch.Size([8])\n",
    "print(t7)  # >>> tensor([0, 1, 2, 3, 4, 5, 6, 7])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:13.053185Z",
     "start_time": "2023-09-18T12:28:12.878366700Z"
    }
   },
   "id": "81108b6198f57a00"
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "torch.Size([2, 6])\n",
      "tensor([[ 0,  1,  2,  6,  7,  8],\n",
      "        [ 3,  4,  5,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "t8 = torch.arange(0, 6).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t9 = torch.arange(6, 12).reshape(2, 3)  # torch.Size([2, 3])\n",
    "\n",
    "# 2차원 텐서간 병합\n",
    "t10 = torch.cat((t8, t9), dim=0) # 0차원에 맞춰서 텐서를 연결한다.\n",
    "print(t10.size())  # >>> torch.Size([4, 3])\n",
    "print(t10)\n",
    "# >>> tensor([[ 0,  1,  2],  <- arange(0,6)\n",
    "#             [ 3,  4,  5],\n",
    "#             [ 6,  7,  8],  <- arange(6,12)\n",
    "#             [ 9, 10, 11]])\n",
    "\n",
    "t11 = torch.cat((t8, t9), dim=1) # 1차원에 맞춰서 텐서를 연결한다.\n",
    "print(t11.size())  # >>>torch.Size([2, 6])\n",
    "print(t11)\n",
    "# >>> tensor([[ 0,  1,  2,  6,  7,  8],\n",
    "#             [ 3,  4,  5,  9, 10, 11]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:13.204506800Z",
     "start_time": "2023-09-18T12:28:13.006656600Z"
    }
   },
   "id": "5926fccf6c0c650b"
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11],\n",
      "        [12, 13, 14],\n",
      "        [15, 16, 17]])\n",
      "torch.Size([2, 9])\n",
      "tensor([[ 0,  1,  2,  6,  7,  8, 12, 13, 14],\n",
      "        [ 3,  4,  5,  9, 10, 11, 15, 16, 17]])\n"
     ]
    }
   ],
   "source": [
    "t12 = torch.arange(0, 6).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t13 = torch.arange(6, 12).reshape(2, 3)  # torch.Size([2, 3])\n",
    "t14 = torch.arange(12, 18).reshape(2, 3)  # torch.Size([2, 3])\n",
    "\n",
    "t15 = torch.cat((t12, t13, t14), dim=0) # 0차원에 맞춰서 세 텐서를 연결한다.\n",
    "print(t15.size())  # >>> torch.Size([6, 3])\n",
    "print(t15)\n",
    "# >>> tensor([[ 0,  1,  2],  <- t12\n",
    "#             [ 3,  4,  5],\n",
    "#             [ 6,  7,  8],  <- t13\n",
    "#             [ 9, 10, 11],\n",
    "#             [12, 13, 14],  <- t14\n",
    "#             [15, 16, 17]])\n",
    "\n",
    "t16 = torch.cat((t12, t13, t14), dim=1) # 1차원에 맞춰서 세 텐서 연결\n",
    "print(t16.size())  # >>> torch.Size([2, 9])\n",
    "print(t16)#       t12          t13        t14\n",
    "# >>> tensor([[ 0,  1,  2,  6,  7,  8, 12, 13, 14],\n",
    "#             [ 3,  4,  5,  9, 10, 11, 15, 16, 17]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:13.372405600Z",
     "start_time": "2023-09-18T12:28:13.185187800Z"
    }
   },
   "id": "a48da9fd7a03245e"
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "torch.Size([1, 4, 3])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "torch.Size([1, 2, 6])\n",
      "tensor([[[ 0,  1,  2,  6,  7,  8],\n",
      "         [ 3,  4,  5,  9, 10, 11]]])\n"
     ]
    }
   ],
   "source": [
    "# 3차원 텐서 간의 cat연산\n",
    "t17 = torch.arange(0, 6).reshape(1, 2, 3)  # torch.Size([1, 2, 3])\n",
    "t18 = torch.arange(6, 12).reshape(1, 2, 3)  # torch.Size([1, 2, 3])\n",
    "\n",
    "t19 = torch.cat((t17, t18), dim=0) # 0차원에 맞춰서 텐서 연결한다.\n",
    "print(t19.size())  # >>> torch.Size([2, 2, 3])\n",
    "print(t19)\n",
    "# >>> tensor([[[ 0,  1,  2],  # 가장 바깥 괄호가 0차원.\n",
    "#              [ 3,  4,  5]],\n",
    "#             [[ 6,  7,  8],\n",
    "#              [ 9, 10, 11]]])\n",
    "\n",
    "t20 = torch.cat((t17, t18), dim=1) # 1차원에 맞춰서 텐서 연결한다.\n",
    "print(t20.size())  # >>> torch.Size([1, 4, 3])\n",
    "print(t20)\n",
    "# >>> tensor([[[ 0,  1,  2],  # 중간 괄호가 1차원\n",
    "#              [ 3,  4,  5],\n",
    "#              [ 6,  7,  8],\n",
    "#              [ 9, 10, 11]]])\n",
    "\n",
    "t21 = torch.cat((t17, t18), dim=2) # 2차원에 맞춰서 텐서 연결한다.\n",
    "print(t21.size())  # >>> torch.Size([1, 2, 6])\n",
    "print(t21)\n",
    "# >>> tensor([[[ 0,  1,  2,  6,  7,  8],  # 가장 안쪽 괄호가 2차원\n",
    "#              [ 3,  4,  5,  9, 10, 11]]])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:13.539786200Z",
     "start_time": "2023-09-18T12:28:13.288005400Z"
    }
   },
   "id": "6a7688a378464fb1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## m_tensor_stacking.py\n",
    "> 새로운 차원으로 확장하여 텐서 시퀀스를 병합한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "beb42e71b4089045"
  },
  {
   "cell_type": "markdown",
   "source": [
    "torch.stack([a,b],dim=0)\n",
    "dim은 확장하고자 하는 차원을 인자로 주면 된다.\n",
    "a와 b는 stacking 하고자 하는 텐서다.\n",
    "\n",
    "dim 위치에 두 텐서를 unsqueeze로 확장하고, cat 연산으로 텐서를 연결하는 것과 같은 결과를 보여준다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91ea6669f5b2591"
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3]) True\n",
      "torch.Size([2, 2, 3]) True\n",
      "torch.Size([2, 3, 2]) True\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t2 = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "t3 = torch.stack([t1, t2], dim=0) # torch.stack 연산\n",
    "t4 = torch.cat([t1.unsqueeze(dim=0), t2.unsqueeze(dim=0)], dim=0)\n",
    "# 두 텐서를 unsqueeze하고 torch.cat으로 연결하는 연산.\n",
    "print(t3.shape, t3.equal(t4))\n",
    "\n",
    "t5 = torch.stack([t1, t2], dim=1) # 확장하고자 하는 차원이 1인 경우\n",
    "t6 = torch.cat([t1.unsqueeze(dim=1), t2.unsqueeze(dim=1)], dim=1)\n",
    "print(t5.shape, t5.equal(t6))\n",
    "\n",
    "t7 = torch.stack([t1, t2], dim=2) # 확장하고자 하는 차원이 2인 경우\n",
    "t8 = torch.cat([t1.unsqueeze(dim=2), t2.unsqueeze(dim=2)], dim=2)\n",
    "print(t7.shape, t7.equal(t8))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:13.799411100Z",
     "start_time": "2023-09-18T12:28:13.756801300Z"
    }
   },
   "id": "8ad15e73e887a5b8"
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "t9 = torch.arange(0, 3)  # tensor([0, 1, 2])\n",
    "t10 = torch.arange(3, 6)  # tensor([3, 4, 5])\n",
    "\n",
    "print(t9.size(), t10.size()) # 둘 모두 1차원 벡터이다.\n",
    "# >>> torch.Size([3]) torch.Size([3])\n",
    "\n",
    "t11 = torch.stack((t9, t10), dim=0) # 0차원을 확장하여 stacking\n",
    "print(t11.size())  # >>> torch.Size([2,3])\n",
    "print(t11)\n",
    "\n",
    "t12 = torch.cat((t9.unsqueeze(0), t10.unsqueeze(0)), dim=0)\n",
    "print(t11.equal(t12))  # stack 연산과 결과가 같다.\n",
    "# >>> True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:14.012459500Z",
     "start_time": "2023-09-18T12:28:13.925191100Z"
    }
   },
   "id": "53901610f9783e72"
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "tensor([[0, 3],\n",
      "        [1, 4],\n",
      "        [2, 5]])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "t13 = torch.stack((t9, t10), dim=1) # 1차원을 확장하여 stacking\n",
    "print(t13.size())  # >>> torch.Size([3,2])\n",
    "print(t13)\n",
    "# >>> tensor([[0, 3],\n",
    "#             [1, 4],\n",
    "#             [2, 5]])\n",
    "t14 = torch.cat((t9.unsqueeze(1), t10.unsqueeze(1)), dim=1)\n",
    "print(t13.equal(t14)) # stack과 연산 결과가 같다.\n",
    "# >>> True\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:14.210553900Z",
     "start_time": "2023-09-18T12:28:14.088462300Z"
    }
   },
   "id": "f89b5d4f8c6b2333"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## n_tensor_vstack_hstack.py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e7c8fe9d1eb7e1b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- vstack: 두 텐서를 위아래로 연결\n",
    "- hstack: 두 텐서를 양옆으로 연결"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "116780f7db2376d8"
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "torch.Size([6, 1])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6]])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([4, 2, 3])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[19, 20, 21],\n",
      "         [22, 23, 24]]])\n"
     ]
    }
   ],
   "source": [
    "# tip. 0 차원을 기준으로 연결하면 된다.\n",
    "t1 = torch.tensor([1, 2, 3]) #->(3)\n",
    "t2 = torch.tensor([4, 5, 6]) #->(3)\n",
    "t3 = torch.vstack((t1, t2)) # 위 아래로 연결-> (2,3)\n",
    "print(t3)\n",
    "\n",
    "t4 = torch.tensor([[1], [2], [3]]) # (3,1)\n",
    "t5 = torch.tensor([[4], [5], [6]]) # (3,1)\n",
    "t6 = torch.vstack((t4, t5)) # 위 아래로 연결 -> (6,1)\n",
    "print(t6.shape)\n",
    "print(t6)\n",
    "\n",
    "t7 = torch.tensor([\n",
    "  [[1, 2, 3], [4, 5, 6]],\n",
    "  [[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "print(t7.shape) # >>> (2, 2, 3)\n",
    "\n",
    "t8 = torch.tensor([\n",
    "  [[13, 14, 15], [16, 17, 18]],\n",
    "  [[19, 20, 21], [22, 23, 24]]\n",
    "])\n",
    "print(t8.shape) # >>> (2, 2, 3)\n",
    "\n",
    "t9 = torch.vstack([t7, t8]) # 위아래로 연결 -> (4, 2, 3)\n",
    "print(t9.shape)\n",
    "print(t9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:14.580216900Z",
     "start_time": "2023-09-18T12:28:14.511292Z"
    }
   },
   "id": "56d06deaee5cb550"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 4, 3])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12],\n",
      "         [19, 20, 21],\n",
      "         [22, 23, 24]]])\n"
     ]
    }
   ],
   "source": [
    "# tip. 1차원을 기준으로 연결하면 된다.\n",
    "t10 = torch.tensor([1, 2, 3]) # ->(3)\n",
    "t11 = torch.tensor([4, 5, 6]) # ->(3)\n",
    "t12 = torch.hstack((t10, t11)) # 양옆으로 연결 ->(6)\n",
    "print(t12)\n",
    "# >>> tensor([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "t13 = torch.tensor([[1], [2], [3]]) # -> (3,1)\n",
    "t14 = torch.tensor([[4], [5], [6]]) # -> (3,1)\n",
    "t15 = torch.hstack((t13, t14)) # 양옆으로 연결 ->(3,2)\n",
    "print(t15)\n",
    "# >>> tensor([[1, 4],\n",
    "#             [2, 5],\n",
    "#             [3, 6]])\n",
    "\n",
    "t16 = torch.tensor([\n",
    "  [[1, 2, 3], [4, 5, 6]],\n",
    "  [[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "print(t16.shape) # >>> (2, 2, 3)\n",
    "\n",
    "t17 = torch.tensor([\n",
    "  [[13, 14, 15], [16, 17, 18]],\n",
    "  [[19, 20, 21], [22, 23, 24]]\n",
    "])\n",
    "print(t17.shape) # >>> (2, 2, 3)\n",
    "\n",
    "t18 = torch.hstack([t16, t17]) # 양옆으로 연결 ->(2, 4, 3)\n",
    "print(t18.shape) # >>> 1차원을 기준으로 연결됨.\n",
    "\n",
    "print(t18)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T12:28:15.370845100Z",
     "start_time": "2023-09-18T12:28:15.278023100Z"
    }
   },
   "id": "7d3b177b715d0720"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 고찰 "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2810a5711307554e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "파이토치의 많은 메소드를 알게 되었다. 특히나 operations이나 stacking에서 매우 유용해 보이는 메소드들을 알게 되었다. stacking 메소드의 원리를 unsqueeze와 cat으로 구현하는 걸 익히며, 이와 비슷하게 텐서를 조작하는 방법은 여러가지가 있겠다는 생각이 들었다. 과제에서는 단순히 메소드만을 배웠지만 앞으로의 수업에서는 이 텐서들을 조작하는 라이브러리를 가지고 필요한 모양으로 텐서를 바꿔가며 사용하리라는 것을 알 수 있었다. 이 연산들, 메소드 들에 많이 익숙해져야 앞으로의 수업 내용을 이해할 수 있으리라 생각한다.\n",
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfe19b6ac020f080"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## 숙제 후기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7a43e1fa49bc008"
  },
  {
   "cell_type": "markdown",
   "source": [
    "jupyter notebook의 사용법이 아직 익숙하지 않아서 조금 어려움이 있었다. 또한 git에 올린 파일을 nbviewer로 로딩하는 것에서 파일 404 에러가 자주떠서 많이 혼란스러움을 느꼈다. 주피터 서버 연결 문제 또는 와이파이 문제로 인해 오류가 나는 것 같다고 생각하고 있다.\n",
    "그러나 주피터 노트북에 익숙해지면서 공부에 많은 효과를 보고 있는 것 같다. 무엇보다도 그 자리에서 궁금한 값에 대해 코드를 짜서 값을 확인해보며 글을 작성할 수 있다는 점이 매우 유용하다. 앞으로 다른 코드들에 대해 정리할 때에도 주피터 노트북을 사용하고자 한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6224b6490d79f1ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e050f91174f89fca"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
