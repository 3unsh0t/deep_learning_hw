{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "##%% md\n",
    " Tensor Initialization\n",
    " \n",
    " > 인용구\n",
    " \n",
    " * 목록\n",
    " + 전부\n",
    " - 동그라미로\n",
    " \n",
    " ---\n",
    " 라인추가\n",
    " \n",
    " <span style=\"color:#F86766D\">글꼴 크기 색 변경</span>\n",
    " <p style=\"font-size: 20px\">폰트사이즈</p>\n",
    " <p style=\"font-style:italic\">기울인 폰트</p>\n",
    " 굵기는 font-weight:bold 하면된다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b34309ff0d35843"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b5c7536832601914"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "################################################## 1\n",
      "torch.int64\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n",
      "################################################## 2\n",
      "torch.Size([]) 0\n",
      "torch.Size([1]) 1\n",
      "torch.Size([5]) 1\n",
      "torch.Size([5, 1]) 2\n",
      "torch.Size([3, 2]) 2\n",
      "torch.Size([3, 2, 1]) 3\n",
      "torch.Size([3, 1, 2, 1]) 4\n",
      "torch.Size([3, 1, 2, 3]) 4\n",
      "torch.Size([3, 1, 2, 3, 1]) 5\n",
      "torch.Size([4, 5]) 2\n",
      "torch.Size([4, 1, 5]) 3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 3 at dim 3 (got 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 99\u001B[0m\n\u001B[0;32m     91\u001B[0m a10 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([                 \u001B[38;5;66;03m# shape: torch.Size([4, 1, 5]), ndims(=rank): 3\u001B[39;00m\n\u001B[0;32m     92\u001B[0m     [[\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m]],\n\u001B[0;32m     93\u001B[0m     [[\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m]],\n\u001B[0;32m     94\u001B[0m     [[\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m]],\n\u001B[0;32m     95\u001B[0m     [[\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m]],\n\u001B[0;32m     96\u001B[0m ])\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28mprint\u001B[39m(a10\u001B[38;5;241m.\u001B[39mshape, a10\u001B[38;5;241m.\u001B[39mndim)\n\u001B[1;32m---> 99\u001B[0m a11 \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43m                 \u001B[49m\u001B[38;5;66;43;03m# ValueError: expected sequence of length 3 at dim 3 (got 2)\u001B[39;49;00m\n\u001B[0;32m    100\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    101\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    102\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    103\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    104\u001B[0m \u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mValueError\u001B[0m: expected sequence of length 3 at dim 3 (got 2)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# torch.Tensor class\n",
    "t1 = torch.Tensor([1, 2, 3], device='cpu')\n",
    "print(t1.dtype)   # >>> torch.float32\n",
    "print(t1.device)  # >>> cpu\n",
    "print(t1.requires_grad)  # >>> False\n",
    "print(t1.size())  # torch.Size([3])\n",
    "print(t1.shape)   # torch.Size([3])\n",
    "\n",
    "# if you have gpu device\n",
    "# t1_cuda = t1.to(torch.device('cuda'))\n",
    "# or you can use shorthand\n",
    "# t1_cuda = t1.cuda()\n",
    "t1_cpu = t1.cpu()\n",
    "\n",
    "print(\"#\" * 50, 1)\n",
    "\n",
    "# torch.tensor function\n",
    "t2 = torch.tensor([1, 2, 3], device='cpu')\n",
    "print(t2.dtype)  # >>> torch.int64\n",
    "print(t2.device)  # >>> cpu\n",
    "print(t2.requires_grad)  # >>> False\n",
    "print(t2.size())  # torch.Size([3])\n",
    "print(t2.shape)  # torch.Size([3])\n",
    "\n",
    "# if you have gpu device\n",
    "# t2_cuda = t2.to(torch.device('cuda'))\n",
    "# or you can use shorthand\n",
    "# t2_cuda = t2.cuda()\n",
    "t2_cpu = t2.cpu()\n",
    "\n",
    "print(\"#\" * 50, 2)\n",
    "\n",
    "a1 = torch.tensor(1)\t\t\t     # shape: torch.Size([]), ndims(=rank): 0\n",
    "print(a1.shape, a1.ndim)\n",
    "\n",
    "a2 = torch.tensor([1])\t\t  \t     # shape: torch.Size([1]), ndims(=rank): 1\n",
    "print(a2.shape, a2.ndim)\n",
    "\n",
    "a3 = torch.tensor([1, 2, 3, 4, 5])   # shape: torch.Size([5]), ndims(=rank): 1\n",
    "print(a3.shape, a3.ndim)\n",
    "\n",
    "a4 = torch.tensor([[1], [2], [3], [4], [5]])   # shape: torch.Size([5, 1]), ndims(=rank): 2\n",
    "print(a4.shape, a4.ndim)\n",
    "\n",
    "a5 = torch.tensor([                 # shape: torch.Size([3, 2]), ndims(=rank): 2\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6]\n",
    "])\n",
    "print(a5.shape, a5.ndim)\n",
    "\n",
    "a6 = torch.tensor([                 # shape: torch.Size([3, 2, 1]), ndims(=rank): 3\n",
    "    [[1], [2]],\n",
    "    [[3], [4]],\n",
    "    [[5], [6]]\n",
    "])\n",
    "print(a6.shape, a6.ndim)\n",
    "\n",
    "a7 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 1]), ndims(=rank): 4\n",
    "    [[[1], [2]]],\n",
    "    [[[3], [4]]],\n",
    "    [[[5], [6]]]\n",
    "])\n",
    "print(a7.shape, a7.ndim)\n",
    "\n",
    "a8 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 3]), ndims(=rank): 4\n",
    "    [[[1, 2, 3], [2, 3, 4]]],\n",
    "    [[[3, 1, 1], [4, 4, 5]]],\n",
    "    [[[5, 6, 2], [6, 3, 1]]]\n",
    "])\n",
    "print(a8.shape, a8.ndim)\n",
    "\n",
    "\n",
    "a9 = torch.tensor([                 # shape: torch.Size([3, 1, 2, 3, 1]), ndims(=rank): 5\n",
    "    [[[[1], [2], [3]], [[2], [3], [4]]]],\n",
    "    [[[[3], [1], [1]], [[4], [4], [5]]]],\n",
    "    [[[[5], [6], [2]], [[6], [3], [1]]]]\n",
    "])\n",
    "print(a9.shape, a9.ndim)\n",
    "\n",
    "a10 = torch.tensor([                 # shape: torch.Size([4, 5]), ndims(=rank): 2\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "])\n",
    "print(a10.shape, a10.ndim)\n",
    "\n",
    "a10 = torch.tensor([                 # shape: torch.Size([4, 1, 5]), ndims(=rank): 3\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "])\n",
    "print(a10.shape, a10.ndim)\n",
    "\n",
    "a11 = torch.tensor([                 # ValueError: expected sequence of length 3 at dim 3 (got 2)\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-14T11:14:32.270322500Z"
    }
   },
   "id": "initial_id"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
